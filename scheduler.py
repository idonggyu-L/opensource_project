import time
import threading
from crawler import run_crawler       # í¬ë¡¤ëŸ¬
from build_db import build_news_db    # DB ë¹Œë”

def update_news(csv_dir="/home/hail/RAG/data", interval=3600, max_pages=5):
    """ì£¼ê¸°ì ìœ¼ë¡œ ë‰´ìŠ¤ í¬ë¡¤ë§ â†’ DB ì—…ë°ì´íŠ¸"""
    def loop():
        while True:
            print("ğŸŒ€ ë‰´ìŠ¤ í¬ë¡¤ë§ + DB ì—…ë°ì´íŠ¸ ì‹œì‘")
            try:
                # 1) ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§ â†’ CSV ì €ì¥
                run_crawler(max_pages=max_pages, output_dir=csv_dir)

                # 2) CSV ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ ë²¡í„° DB ì¬êµ¬ì¶•
                build_news_db(csv_dir)
                print("âœ… ë‰´ìŠ¤ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

            # interval ë§Œí¼ ëŒ€ê¸°
            time.sleep(interval)

    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    thread = threading.Thread(target=loop, daemon=True)
    thread.start()
